{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umělé neuronové sítě typu MLP\n",
    "\n",
    "Pro získání bonusového bodu je potřeba dosáhnout s ReLU aktivační funkci úspěšnosti > 90%. Pro tento účel je nutné odladit hodnotu parametru $\\alpha$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.612295Z",
     "end_time": "2023-05-30T22:55:43.791218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['x', 'xTest', 'y', 'yTest', 'w1', 'w2']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "npzfile = np.load('data/data_10.npz')\n",
    "npzfile.files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.765940Z",
     "end_time": "2023-05-30T22:55:43.791343Z"
    }
   },
   "outputs": [],
   "source": [
    "x = npzfile['x']\n",
    "xTest = npzfile['xTest']\n",
    "\n",
    "y = npzfile['y']\n",
    "yTest = npzfile['yTest']\n",
    "\n",
    "x.shape, y.shape\n",
    "\n",
    "w1test = npzfile['w1']\n",
    "w2test = npzfile['w2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkce sigmoid\n",
    "\n",
    "$$ sigmoid(u) = \\sigma (u) = \\frac{e^u}{1+e^u} = \\frac{1}{1+e^{-u}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.765978Z",
     "end_time": "2023-05-30T22:55:43.791396Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "\n",
    "    sig = np.exp(u)/(1+np.exp(u))\n",
    "\n",
    "    return sig\n",
    "\n",
    "    #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.766006Z",
     "end_time": "2023-05-30T22:55:43.791518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.73105858, 0.88079708],\n       [0.04742587, 0.01798621]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "u = np.array([[1,2],[-3,-4]])\n",
    "sigmoid(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.73105858, 0.88079708],\n",
    "       [0.04742587, 0.01798621]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivace funkce sigmoid:\n",
    "$$ \\sigma' (u) = \\sigma (u) (1 - \\sigma(u)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.766040Z",
     "end_time": "2023-05-30T22:55:43.791575Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_grad(u):\n",
    "\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "\n",
    "    grad = sigmoid(u)*(1-sigmoid(u))\n",
    "\n",
    "    return grad\n",
    "\n",
    "    #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.766067Z",
     "end_time": "2023-05-30T22:55:43.791685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.19661193, 0.10499359],\n       [0.04517666, 0.01766271]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "sigmoid_grad(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.19661193, 0.10499359],\n",
    "       [0.04517666, 0.01766271]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "\n",
    "$$ f(u) = max(0, u) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.766131Z",
     "end_time": "2023-05-30T22:55:43.809461Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "\n",
    "    relu = np.maximum(0,u)\n",
    "\n",
    "    return relu\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.809356Z",
     "end_time": "2023-05-30T22:55:43.809739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 2],\n       [0, 0]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "relu(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[1, 2],\n",
    "       [0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivace funkce ReLU:\n",
    "$$ f'(x) = \\boldsymbol{1} (x \\ge 0)$$\n",
    "\n",
    "Derivace přímo v bodě nula je dodefinována na hodnotu nula.\n",
    "\n",
    "Gradient se přes tento blok přenáší:\n",
    "1) Nezměněný, pokud je hodnota na vstupu z dopředného průchodu větší než nula.\n",
    "2) Přenesená hodnota je nula, pokud je hodnota na vstupu z dopředného průchodu menší nebo rovna nule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.809432Z",
     "end_time": "2023-05-30T22:55:43.809804Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu_grad(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    grad = (u > 0)\n",
    "    return grad\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.809532Z",
     "end_time": "2023-05-30T22:55:43.809948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ True,  True],\n       [False, False]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "relu_grad(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[ True,  True],\n",
    "       [False, False]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "$ \\pi $ nabývá hodnoty 1 pouze pro jednu třídu. Např. máme celkem 3 třídy (0, 1, 2): $\\pi_0 = [0,1,0]$  pro $y_0 = 1$\n",
    "\n",
    "\n",
    "$$\n",
    "    classes = \n",
    "        \\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        0 \\\\\n",
    "        2\\\\\n",
    "        1 \\\\\n",
    "        \\end{bmatrix} \n",
    "    \\implies\n",
    "        \\pi = \n",
    "        \\begin{bmatrix}\n",
    "        0 & 1 & 0 \\\\\n",
    "        1 & 0 & 0 \\\\\n",
    "        0 & 0 & 1 \\\\\n",
    "        0 & 1 & 0 \\\\\n",
    "        \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.809608Z",
     "end_time": "2023-05-30T22:55:43.810002Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    data = np.array(data)\n",
    "    one_hot = np.zeros((data.size, data.max()+1))\n",
    "    for i in range(data.size):\n",
    "        one_hot[i,data[i]] = 1\n",
    "\n",
    "    return one_hot\n",
    "    #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.809654Z",
     "end_time": "2023-05-30T22:55:43.863714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "encoded = one_hot_encoding(y)\n",
    "encoded[[0,900,1800,2700,3500,4200],:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "- Funkce softmax má c vstupů a c výstupů. \n",
    "- Všechny výstupy jsou kladná čísla. \n",
    "- Součet všech výstupů dohromady je roven číslu 1.\n",
    "$$\\widehat{y_c} = softmax(u) = \\frac{e^{u_c}}{\\sum_{d=0}^{c} {e^{u_d}}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.814128Z",
     "end_time": "2023-05-30T22:55:43.864020Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(u):\n",
    "    \"\"\"\n",
    "    softmax !radkove!\n",
    "    \"\"\"\n",
    "    #################################################################\n",
    "    # ZDE DOPLNI\n",
    "    e = np.exp(u)\n",
    "    y = e / np.array(np.sum(e,axis=1), ndmin=2).T\n",
    "    return y\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.816240Z",
     "end_time": "2023-05-30T22:55:43.864808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.26894142, 0.73105858],\n       [0.73105858, 0.26894142]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "softmax(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.26894142, 0.73105858],\n",
    "       [0.5       , 0.5       ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.824335Z",
     "end_time": "2023-05-30T22:55:43.864944Z"
    }
   },
   "outputs": [],
   "source": [
    "def theta_grad(grad_on_output, input_data):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    weight_grad = np.dot(input_data.T, grad_on_output).T\n",
    "    bias_grad = np.sum(grad_on_output, axis=0)\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    return weight_grad, bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.831059Z",
     "end_time": "2023-05-30T22:55:43.935360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "(2, 3)\n",
      "(3, 4)\n",
      "[[43 48 20  9]\n",
      " [32 36 16  6]\n",
      " [75 84 36 15]]\n",
      "(3,)\n",
      "[5 4 9]\n"
     ]
    }
   ],
   "source": [
    "#test vypoctu gradientu pro matici vah a biasy\n",
    "\n",
    "#dva vstupni vektory, kazdy ma 4 hodnoty, cili jde o vrstvu, kde kazdy neuron ma 4 vstupy\n",
    "input_test = np.array([[7,8,4,1],[9,10,4,2]])\n",
    "print(input_test.shape)\n",
    "\n",
    "#dva gradienty na vystupu, kazdy ma 3 hodnoty, cili jde o vrstvu, ktera ma 3 neurony [a kazdy ma 4 vstupy])\n",
    "grad_on_output_test = np.array([[1,2,3],[4,2,6]])\n",
    "print(grad_on_output_test.shape)\n",
    "\n",
    "w_grad_test,u_grad_test = theta_grad(grad_on_output_test,input_test)\n",
    "\n",
    "#gradienu vektoru vah ma tedy rozmery 3*4\n",
    "print(w_grad_test.shape)\n",
    "print(w_grad_test)\n",
    "\n",
    "#gradient biasu ma 3 hodnoty\n",
    "print(u_grad_test.shape)\n",
    "print(u_grad_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(2, 4)\n",
    "(2, 3)\n",
    "(3, 4)\n",
    "[[43 48 20  9]\n",
    " [32 36 16  6]\n",
    " [75 84 36 15]]\n",
    "(3,)\n",
    "[5 4 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sítě typu vícevrstvý perceptron = Multi-Layer Perceptron (MLP)\n",
    "\n",
    "\n",
    "\n",
    "### Předzpracování dat\n",
    "Pro trénování neuronových sítí je vhodné provádět standardizaci dat na nulovou střední hodnotu a jednotkový rozptyl.\n",
    "\n",
    "### Inicializace parametrů (váhových koeficientů)\n",
    "- Váhy neuronů nesmí být nastaveny na stejné hodnoty (např. 0), aby neměly stejnou hodnotu výstupu a stejný gradient\n",
    "=>\n",
    "- Je třeba porušit symetrii:\n",
    "    - Váhy se inicializují jako malá náhodná čísla (polovina kladná, polovina záporná)\n",
    "    - V praxi se pro ReLU používá hodnota $randn(n) * sqrt(2.0/n)$, kde n je počet vstupů neuronu\n",
    "    - Započítání počtu vstupů pak zajišťuje, že neurony s různým počtem vstupů mají výstup se stejným rozptylem hodnot\n",
    "    - Biasy se inicializují na hodnotu 0 nebo 0.01 (symetrie je již porušena inicializací váhových koeficientů)\n",
    "\n",
    "### Dopředný průchod\n",
    "Kroky:\n",
    "1. $u_1 = \\theta_1^T x_1$ (vstupní vrstva)\n",
    "2. $a_1 = ReLU(u_1)$ (aktivační funkce)\n",
    "3. $u_2 = \\theta_2^T a_1$ (skrytá vrstva)\n",
    "4. $\\tilde{y} = softmax(u_2)$ (výstupní vrstva)\n",
    "\n",
    "Na výstupu vznikne podle zvoleného kritéria chyba či odchylka\n",
    "\n",
    "### Zpětný průchod\n",
    "\n",
    "(hodnoty z dopředného průhodu $a_1$ a $u_2$ je vhodné si během dopředného průchodu uložit)\n",
    "\n",
    "1. $du_2 = softmax(x)-\\pi(y)$\n",
    "\n",
    "2. $dW_2 = du_2^T a_1$  a  $db_2 = du_2 $\n",
    "\n",
    "3. $da_1 = W_2^T du_2$\n",
    "\n",
    "4. $du_1 = relu'(da_1) = relu'(W_2^T du_2)$\n",
    "\n",
    "5. $dW_1 = du_1^T x$  a  $db = du_1 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.837967Z",
     "end_time": "2023-05-30T22:55:43.935510Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "class TwoLayerPerceptron:\n",
    "    def __init__ (self, input_data, classes, \n",
    "                  test_data, test_classes,\n",
    "                  input_layer_size, hidden_layer_size, output_size,\n",
    "                  activation_function, activation_function_derivation, alpha=0.00015, lmbd=0):\n",
    "    \n",
    "        self.input_data = input_data\n",
    "        self.classes = classes\n",
    "        \n",
    "        self.test_data = test_data\n",
    "        self.test_classes = test_classes\n",
    "        \n",
    "        self.w1 = np.random.rand(hidden_layer_size, input_layer_size + 1) * np.sqrt(2. / input_layer_size)\n",
    "        self.w2 = np.random.rand(output_size, hidden_layer_size + 1) * np.sqrt(2. / hidden_layer_size)\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_derivation = activation_function_derivation\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.lmbd = lmbd\n",
    "        \n",
    "    def forward(self, mode='training'):\n",
    "        if mode == 'training':\n",
    "            x = self.input_data\n",
    "        else:\n",
    "            x = self.test_data\n",
    "\n",
    "        #1. vrstva\n",
    "        #x1 = ... #nezapomente na bias(prvni sloupec) #4500x401\n",
    "        #u1 = ...\n",
    "\n",
    "        x1 = np.hstack((np.ones((x.shape[0],1)),x))\n",
    "        #print(\"x1 \", x1.shape)\n",
    "        #print(x1[:,0:4])\n",
    "        u1 = np.dot(x1,self.w1.T)\n",
    "        #print(\"u1 \", u1.shape)\n",
    "        #print(u1[:,0:4])\n",
    "\n",
    "        #aktivacni funkce pomocí funkce self.activation_function\n",
    "        #a1 = ... #4500x25\n",
    "        a1 = self.activation_function(u1)\n",
    "        #print(\"a1 \", a1.shape)\n",
    "        #print(a1[0])\n",
    "\n",
    "        #2. vrstva (skryta vrstva)\n",
    "        #x2 = ... #4500x26\n",
    "        #u2 = ...\n",
    "\n",
    "        x2 = np.hstack((np.ones((a1.shape[0],1)),a1))\n",
    "        #print(\"x2 \", x2.shape)\n",
    "        u2 = np.dot(x2,self.w2.T)\n",
    "\n",
    "\n",
    "        #vystup po softmaxu\n",
    "        #scores = ... #4500x10 scores pro kazdou tridu\n",
    "        scores = softmax(u2)\n",
    "        \n",
    "        #cache\n",
    "        self.scores = scores\n",
    "        self.a1 = a1\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        #pomocí self.scores, self.classes a one_hot_encoding \n",
    "        du2 = self.scores - one_hot_encoding(self.classes)\n",
    "        #print(\"du2\", du2[3,0:4])\n",
    "\n",
    "        #pomocí funkce theta_grad\n",
    "        #dw2, db2 = ...\n",
    "        dw2, db2 = theta_grad(du2,self.a1)\n",
    "\n",
    "        #da1 = ...\n",
    "        da1 = np.dot(du2,self.w2)\n",
    "        da1 = da1[:,1:]\n",
    "        \n",
    "        #pomocí funkce self.activation_function_derivation\n",
    "        #POZOR: tato funce se musí aplikovat na vstupní hodnotu z dopředného průchodu !!\n",
    "        #print(\"da1\", da1[1,0:4])\n",
    "        du1 = self.activation_function_derivation(self.a1) * da1\n",
    "\n",
    "        #print(\"du1\", du1[1,0:4])\n",
    "\n",
    "        #pomocí funkce theta_grad\n",
    "        dw1, db1 = theta_grad(du1,self.input_data)\n",
    "\n",
    "        #print(\"db1[0:4]\", db1[0:4])\n",
    "\n",
    "        m = self.input_data.shape[0]\n",
    "\n",
    "        dw1_reg = (self.lmbd / m) * dw1\n",
    "        dw2_reg = (self.lmbd / m) * dw2\n",
    "\n",
    "        dw1 = dw1 + dw1_reg\n",
    "        dw2 = dw2 + dw2_reg\n",
    "\n",
    "        #print(\"dw1\", dw1[3,0:4])\n",
    "\n",
    "        #POZOR: dw2 není gradient celé matice w2 ale pouze její části\n",
    "        #gradient celé matice w2 pro update vah vznikne vhodným spojením dw2 a db2\n",
    "\n",
    "        db2 = db2.reshape(-1, 1)\n",
    "        w2 = np.hstack((db2, dw2))\n",
    "        \n",
    "        #obdobně dw1 není gradient celé matice w1 !!\n",
    "        w1 = np.hstack((db1.reshape(-1, 1), dw1))\n",
    "\n",
    "        self.w1 -= self.alpha * w1\n",
    "        self.w2 -= self.alpha * w2\n",
    "\n",
    "        # self.w1 = w1\n",
    "        # self.w2 = w2\n",
    "\n",
    "        return self.w1, self.w2\n",
    "    \n",
    "    def accuracy(self):\n",
    "        scores = self.forward('test')\n",
    "        predicted_classes = np.argmax(scores,axis=1)\n",
    "        return (predicted_classes==self.test_classes.T).mean() * 100\n",
    "    \n",
    "    def setWeigtsForTest(self,w1,w2):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "            \n",
    "#################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.879240Z",
     "end_time": "2023-05-30T22:55:43.935576Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "output_size = len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.879302Z",
     "end_time": "2023-05-30T22:55:43.971946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.88910953e-01 1.18307825e-04 9.44813682e-01 9.87532276e-01\n",
      " 9.61459910e-01 1.31154023e-02 9.79568046e-01 7.05262715e-01\n",
      " 5.76467884e-03 9.19662205e-01 9.97263993e-01 9.08968353e-01\n",
      " 3.54340337e-03 1.54639813e-01 3.48157918e-03 9.64035515e-01\n",
      " 6.28337854e-04 7.80228020e-03 1.46816393e-01 9.29857033e-01\n",
      " 9.88740224e-01 4.21889681e-02 9.95978182e-01 1.23596237e-02\n",
      " 3.08083417e-02]\n",
      "[1.70049726e-05 1.30427018e-04 6.67761717e-07 2.30092641e-02\n",
      " 5.11252228e-03 3.23657653e-04 2.31894141e-04 5.87981895e-04\n",
      " 9.70496699e-01 8.98808528e-05]\n",
      "w1[1,3:10]\n",
      "[ 1.04748295e-06 -6.14212351e-06 -3.10738969e-05 -5.12334111e-04\n",
      " -1.01522623e-03 -1.00762293e-03  1.39424437e-04]\n",
      "w2[2,:]\n",
      "[-0.68914772 -1.94520592  2.01354627 -3.12305302 -0.23607182  1.38710368\n",
      "  0.90998378 -1.54772406 -0.79831546 -0.65586508  0.73546763 -2.58591928\n",
      "  0.47228113  0.55369292  2.51279944 -2.41670639 -1.63893467  1.20278107\n",
      " -1.20262867 -1.83449526 -1.88014107 -0.34043256  0.23704342 -1.0611528\n",
      "  1.02771983 -0.47677771]\n"
     ]
    }
   ],
   "source": [
    "#Instance pro odladění:\n",
    "\n",
    "testTlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size, \n",
    "                         sigmoid, sigmoid_grad, \n",
    "                         alpha = 0.00005, lmbd=0)\n",
    "testTlp.setWeigtsForTest(w1test,w2test)\n",
    "\n",
    "scores = testTlp.forward()\n",
    "print(testTlp.a1[0]) \n",
    "print(scores[3]) \n",
    "w1, w2 = testTlp.backward()\n",
    "print(\"w1[1,3:10]\")\n",
    "print(w1[1,3:10])\n",
    "print(\"w2[2,:]\")\n",
    "print(w2[2,:])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro ladění:\n",
    "forward:\n",
    "x1[:,0:4]\n",
    "[[1. 0. 0. 0.]\n",
    " [1. 0. 0. 0.]\n",
    " [1. 0. 0. 0.]\n",
    " ...\n",
    " [1. 0. 0. 0.]\n",
    " [1. 0. 0. 0.]\n",
    " [1. 0. 0. 0.]]\n",
    "u1[:,0:4]\n",
    "[[ 4.49064643 -9.04210233  2.84027269  4.37206593]\n",
    " [ 0.81171744 -1.89711703  1.85454769  2.70242974]\n",
    " [-4.92204922  1.62505363 -1.63987317  3.34948622]\n",
    " ...\n",
    " [-5.11646089 -2.62684399  4.66054153  5.41543074]\n",
    " [-0.7061599  -2.91871491 -1.52511379 -0.22418914]\n",
    " [ 1.76313448 -6.87709282  3.74244317  3.69964681]]\n",
    "a1[0]\n",
    "[9.88910953e-01 1.18307825e-04 9.44813682e-01 9.87532276e-01\n",
    " 9.61459910e-01 1.31154023e-02 9.79568046e-01 7.05262715e-01\n",
    " 5.76467884e-03 9.19662205e-01 9.97263993e-01 9.08968353e-01\n",
    " 3.54340337e-03 1.54639813e-01 3.48157918e-03 9.64035515e-01\n",
    " 6.28337854e-04 7.80228020e-03 1.46816393e-01 9.29857033e-01\n",
    " 9.88740224e-01 4.21889681e-02 9.95978182e-01 1.23596237e-02\n",
    " 3.08083417e-02]\n",
    "x2[:,0:4]\n",
    "[[1.00000000e+00 9.88910953e-01 1.18307825e-04 9.44813682e-01]\n",
    " [1.00000000e+00 6.92475360e-01 1.30435117e-01 8.64660171e-01]\n",
    " [1.00000000e+00 7.23151291e-03 8.35490908e-01 1.62482321e-01]\n",
    " ...\n",
    " [1.00000000e+00 5.96145805e-03 6.74306419e-02 9.90627340e-01]\n",
    " [1.00000000e+00 3.30447917e-01 5.12361344e-02 1.78709722e-01]\n",
    " [1.00000000e+00 8.53601797e-01 1.03007524e-03 9.76852371e-01]]\n",
    "u2[:,0:4]\n",
    "[[ -9.3676932   -6.38107877 -12.6179903    5.60001973]\n",
    " [ -2.87539171  -2.53341895  -6.38845969  -4.79830061]\n",
    " [ -5.1814231   -7.11402377   2.61876464  -9.11359119]\n",
    " ...\n",
    " [ -5.58171484  -3.30391879  -4.94701057 -10.62168707]\n",
    " [ -1.27735949  -0.34901449  -3.49339797  -8.81367006]\n",
    " [ -5.51804473  -4.09046134  -9.65245961  -6.42219279]]\n",
    "scores[3]\n",
    "[1.70049726e-05 1.30427018e-04 6.67761717e-07 2.30092641e-02\n",
    " 5.11252228e-03 3.23657653e-04 2.31894141e-04 5.87981895e-04\n",
    " 9.70496699e-01 8.98808528e-05]\n",
    " \n",
    "backward:\n",
    "du2[3,0:4]\n",
    "[1.70049726e-05 1.30427018e-04 6.67761717e-07 2.30092641e-02]\n",
    "dw2[3,0:4]\n",
    "[-1.03220314 -2.1725677  -0.64194913  0.6108072 ]\n",
    "db2[0:4]\n",
    "[ 8.88586683 -1.67675408 -3.85991324 -0.11891478]\n",
    "da1[1,0:4]\n",
    "[-0.0516748   0.03879986  0.01025437 -0.01587243]\n",
    "du1[1,0:4]\n",
    "[-0.01148586  0.00965883  0.00213838 -0.00321013]\n",
    "dw1[3,0:4]\n",
    "[0.00000000e+00 0.00000000e+00 2.93908380e-08 3.99038593e-05]\n",
    "db1[0:4]\n",
    "[-1.83808322 -1.89853117 -0.26354143  1.66833278]\n",
    "\n",
    "výsledek:\n",
    "w1[1,3:10]\n",
    "[ 1.04783135e-06 -6.15187918e-06 -3.09972922e-05 -5.11502892e-04\n",
    " -1.01684694e-03 -1.00431299e-03  1.41514706e-04]\n",
    "w2[2,:]\n",
    "[-0.68741076 -1.94362559  2.01300712 -3.12207333 -0.23513146  1.38975155\n",
    "  0.91141916 -1.54754314 -0.79837387 -0.65466578  0.73622662 -2.58579641\n",
    "  0.47383578  0.55547437  2.51500361 -2.41635527 -1.63847029  1.20323884\n",
    " -1.20416007 -1.83481622 -1.88023829 -0.33927671  0.23811071 -1.05911533\n",
    "  1.02886739 -0.47560228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:43.925895Z",
     "end_time": "2023-05-30T22:55:48.138371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid testovaci mnozina : 86.8\n"
     ]
    }
   ],
   "source": [
    "tlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size, \n",
    "                         sigmoid, sigmoid_grad, \n",
    "                         alpha = 0.0003, lmbd=0.002)\n",
    "\n",
    "nIter = 150\n",
    "#################################################################\n",
    "\n",
    "for i in range(nIter):\n",
    "            \n",
    "    scores = tlp.forward()\n",
    "    w1, w2 = tlp.backward()\n",
    "    \n",
    "pred = tlp.accuracy()\n",
    "#################################################################\n",
    "print(f\"sigmoid testovaci mnozina : {pred}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T23:05:41.440263Z",
     "end_time": "2023-05-30T23:05:44.645922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu testovaci mnozina : 90.2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42) # nutnost nastavit seed, jinak to skace i treba o 10 procent\n",
    "tlp = TwoLayerPerceptron(x, y, xTest, yTest,\n",
    "                         input_layer_size, hidden_layer_size, output_size,\n",
    "                         relu, relu_grad, 0.00011, 0)\n",
    "\n",
    "nIter = 150\n",
    "#################################################################\n",
    "\n",
    "for i in range(nIter):\n",
    "            \n",
    "    scores = tlp.forward()\n",
    "    w1, w2 = tlp.backward()\n",
    "    \n",
    "pred = tlp.accuracy()\n",
    "#################################################################\n",
    "print(f\"relu testovaci mnozina : {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:51.522292Z",
     "end_time": "2023-05-30T22:55:51.525061Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:51.524437Z",
     "end_time": "2023-05-30T22:55:51.527237Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T22:55:51.527285Z",
     "end_time": "2023-05-30T22:55:51.529389Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
