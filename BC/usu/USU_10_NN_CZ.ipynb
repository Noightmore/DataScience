{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umělé neuronové sítě typu MLP\n",
    "\n",
    "Pro získání bonusového bodu je potřeba dosáhnout s ReLU aktivační funkci úspěšnosti > 90%. Pro tento účel je nutné odladit hodnotu parametru $\\alpha$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:19:36.006606280Z",
     "start_time": "2023-05-23T13:19:35.789698208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['x', 'xTest', 'y', 'yTest', 'w1', 'w2']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "npzfile = np.load('data/data_10.npz')\n",
    "npzfile.files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:19:37.454949795Z",
     "start_time": "2023-05-23T13:19:37.380423095Z"
    }
   },
   "outputs": [],
   "source": [
    "x = npzfile['x']\n",
    "xTest = npzfile['xTest']\n",
    "\n",
    "y = npzfile['y']\n",
    "yTest = npzfile['yTest']\n",
    "\n",
    "x.shape, y.shape\n",
    "\n",
    "w1test = npzfile['w1']\n",
    "w2test = npzfile['w2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkce sigmoid\n",
    "\n",
    "$$ sigmoid(u) = \\sigma (u) = \\frac{e^u}{1+e^u} = \\frac{1}{1+e^{-u}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:08.405850922Z",
     "start_time": "2023-05-23T13:20:08.394971592Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    sig = np.exp(u)/(1+np.exp(u))\n",
    "\n",
    "    return sig\n",
    "\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:09.926107171Z",
     "start_time": "2023-05-23T13:20:09.914999063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.73105858, 0.88079708],\n       [0.04742587, 0.01798621]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "u = np.array([[1,2],[-3,-4]])\n",
    "sigmoid(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.73105858, 0.88079708],\n",
    "       [0.04742587, 0.01798621]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivace funkce sigmoid:\n",
    "$$ \\sigma' (u) = \\sigma (u) (1 - \\sigma(u)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:20.544091058Z",
     "start_time": "2023-05-23T13:20:20.531671374Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_grad(u):\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    grad = sigmoid(u)*(1-sigmoid(u))\n",
    "    \n",
    "    return grad\n",
    "\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:17.403137360Z",
     "start_time": "2023-05-23T13:20:17.397506671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.19661193, 0.10499359],\n       [0.04517666, 0.01766271]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "sigmoid_grad(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.19661193, 0.10499359],\n",
    "       [0.04517666, 0.01766271]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "\n",
    "$$ f(u) = max(0, u) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:22.664829905Z",
     "start_time": "2023-05-23T13:20:22.653230806Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    relu = np.maximum(0,u)\n",
    "    \n",
    "    return relu\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:24.357672062Z",
     "start_time": "2023-05-23T13:20:24.309656512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 2],\n       [0, 0]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "relu(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[1, 2],\n",
    "       [0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivace funkce ReLU:\n",
    "$$ f'(x) = \\boldsymbol{1} (x \\ge 0)$$\n",
    "\n",
    "Derivace přímo v bodě nula je dodefinována na hodnotu nula.\n",
    "\n",
    "Gradient se přes tento blok přenáší:\n",
    "1) Nezměněný, pokud je hodnota na vstupu z dopředného průchodu větší než nula.\n",
    "2) Přenesená hodnota je nula, pokud je hodnota na vstupu z dopředného průchodu menší nebo rovna nule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:27.985382141Z",
     "start_time": "2023-05-23T13:20:27.975548327Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu_grad(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    grad = (u > 0)\n",
    "    return grad\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:29.724393155Z",
     "start_time": "2023-05-23T13:20:29.712709742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ True,  True],\n       [False, False]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "relu_grad(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[ True,  True],\n",
    "       [False, False]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "$ \\pi $ nabývá hodnoty 1 pouze pro jednu třídu. Např. máme celkem 3 třídy (0, 1, 2): $\\pi_0 = [0,1,0]$  pro $y_0 = 1$\n",
    "\n",
    "\n",
    "$$\n",
    "    classes = \n",
    "        \\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        0 \\\\\n",
    "        2\\\\\n",
    "        1 \\\\\n",
    "        \\end{bmatrix} \n",
    "    \\implies\n",
    "        \\pi = \n",
    "        \\begin{bmatrix}\n",
    "        0 & 1 & 0 \\\\\n",
    "        1 & 0 & 0 \\\\\n",
    "        0 & 0 & 1 \\\\\n",
    "        0 & 1 & 0 \\\\\n",
    "        \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:33.673977540Z",
     "start_time": "2023-05-23T13:20:33.662482446Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    data = np.array(data)\n",
    "    one_hot = np.zeros((data.size, data.max()+1))\n",
    "    for i in range(data.size):\n",
    "        one_hot[i,data[i]] = 1\n",
    "    \n",
    "    return one_hot\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:35.880525795Z",
     "start_time": "2023-05-23T13:20:35.848336224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "encoded = one_hot_encoding(y)\n",
    "encoded[[0,900,1800,2700,3500,4200],:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "- Funkce softmax má c vstupů a c výstupů. \n",
    "- Všechny výstupy jsou kladná čísla. \n",
    "- Součet všech výstupů dohromady je roven číslu 1.\n",
    "$$\\widehat{y_c} = softmax(u) = \\frac{e^{u_c}}{\\sum_{d=0}^{c} {e^{u_d}}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:41.456103323Z",
     "start_time": "2023-05-23T13:20:41.444509746Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(u):\n",
    "    \"\"\"\n",
    "    softmax !radkove!\n",
    "    \"\"\"\n",
    "    #################################################################\n",
    "    # ZDE DOPLNI\n",
    "    e = np.exp(u)\n",
    "    y = e / np.array(np.sum(e,axis=1), ndmin=2).T\n",
    "    return y\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T13:20:43.943147273Z",
     "start_time": "2023-05-23T13:20:43.920149699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.26894142, 0.73105858],\n       [0.73105858, 0.26894142]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "softmax(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.26894142, 0.73105858],\n",
    "       [0.5       , 0.5       ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-25T17:51:52.243099Z",
     "end_time": "2023-05-25T17:51:52.254849Z"
    }
   },
   "outputs": [],
   "source": [
    "def theta_grad(grad_on_output, input_data):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    weight_grad = np.dot(input_data.T, grad_on_output).T\n",
    "    bias_grad = np.sum(grad_on_output, axis=0)\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    return weight_grad, bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-25T17:51:54.652018Z",
     "end_time": "2023-05-25T17:51:54.660686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "(2, 3)\n",
      "(3, 4)\n",
      "[[43 48 20  9]\n",
      " [32 36 16  6]\n",
      " [75 84 36 15]]\n",
      "(3,)\n",
      "[5 4 9]\n"
     ]
    }
   ],
   "source": [
    "#test vypoctu gradientu pro matici vah a biasy\n",
    "\n",
    "#dva vstupni vektory, kazdy ma 4 hodnoty, cili jde o vrstvu, kde kazdy neuron ma 4 vstupy\n",
    "input_test = np.array([[7,8,4,1],[9,10,4,2]])\n",
    "print(input_test.shape)\n",
    "\n",
    "#dva gradienty na vystupu, kazdy ma 3 hodnoty, cili jde o vrstvu, ktera ma 3 neurony [a kazdy ma 4 vstupy])\n",
    "grad_on_output_test = np.array([[1,2,3],[4,2,6]])\n",
    "print(grad_on_output_test.shape)\n",
    "\n",
    "w_grad_test,u_grad_test = theta_grad(grad_on_output_test,input_test)\n",
    "\n",
    "#gradienu vektoru vah ma tedy rozmery 3*4\n",
    "print(w_grad_test.shape)\n",
    "print(w_grad_test)\n",
    "\n",
    "#gradient biasu ma 3 hodnoty\n",
    "print(u_grad_test.shape)\n",
    "print(u_grad_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(2, 4)\n",
    "(2, 3)\n",
    "(3, 4)\n",
    "[[43 48 20  9]\n",
    " [32 36 16  6]\n",
    " [75 84 36 15]]\n",
    "(3,)\n",
    "[5 4 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sítě typu vícevrstvý perceptron = Multi-Layer Perceptron (MLP)\n",
    "\n",
    "\n",
    "\n",
    "### Předzpracování dat\n",
    "Pro trénování neuronových sítí je vhodné provádět standardizaci dat na nulovou střední hodnotu a jednotkový rozptyl.\n",
    "\n",
    "### Inicializace parametrů (váhových koeficientů)\n",
    "- Váhy neuronů nesmí být nastaveny na stejné hodnoty (např. 0), aby neměly stejnou hodnotu výstupu a stejný gradient\n",
    "=>\n",
    "- Je třeba porušit symetrii:\n",
    "    - Váhy se inicializují jako malá náhodná čísla (polovina kladná, polovina záporná)\n",
    "    - V praxi se pro ReLU používá hodnota $randn(n) * sqrt(2.0/n)$, kde n je počet vstupů neuronu\n",
    "    - Započítání počtu vstupů pak zajišťuje, že neurony s různým počtem vstupů mají výstup se stejným rozptylem hodnot\n",
    "    - Biasy se inicializují na hodnotu 0 nebo 0.01 (symetrie je již porušena inicializací váhových koeficientů)\n",
    "\n",
    "### Dopředný průchod\n",
    "Kroky:\n",
    "1. $u_1 = \\theta_1^T x_1$ (vstupní vrstva)\n",
    "2. $a_1 = ReLU(u_1)$ (aktivační funkce)\n",
    "3. $u_2 = \\theta_2^T a_1$ (skrytá vrstva)\n",
    "4. $\\tilde{y} = softmax(u_2)$ (výstupní vrstva)\n",
    "\n",
    "Na výstupu vznikne podle zvoleného kritéria chyba či odchylka\n",
    "\n",
    "### Zpětný průchod\n",
    "\n",
    "(hodnoty z dopředného průhodu $a_1$ a $u_2$ je vhodné si během dopředného průchodu uložit)\n",
    "\n",
    "1. $du_2 = softmax(x)-\\pi(y)$\n",
    "\n",
    "2. $dW_2 = du_2^T a_1$  a  $db_2 = du_2 $\n",
    "\n",
    "3. $da_1 = W_2^T du_2$\n",
    "\n",
    "4. $du_1 = relu'(da_1) = relu'(W_2^T du_2)$\n",
    "\n",
    "5. $dW_1 = du_1^T x$  a  $db = du_1 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-25T19:33:53.282846Z",
     "end_time": "2023-05-25T19:33:53.295758Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "class TwoLayerPerceptron:\n",
    "    def __init__ (self, input_data, classes, \n",
    "                  test_data, test_classes,\n",
    "                  input_layer_size, hidden_layer_size, output_size,\n",
    "                  activation_function, activation_function_derivation, alpha=0.00015, lmbd=0):\n",
    "    \n",
    "        self.input_data = input_data\n",
    "        self.classes = classes\n",
    "        \n",
    "        self.test_data = test_data\n",
    "        self.test_classes = test_classes\n",
    "        \n",
    "        self.w1 = np.random.rand(hidden_layer_size, input_layer_size + 1) * np.sqrt(2. / input_layer_size)\n",
    "        self.w2 = np.random.rand(output_size, hidden_layer_size + 1) * np.sqrt(2. / hidden_layer_size)\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_derivation = activation_function_derivation\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.lmbd = lmbd\n",
    "        \n",
    "    # def forward(self, mode='training'):\n",
    "    #     if(mode=='training'):\n",
    "    #         x = self.input_data\n",
    "    #     else:\n",
    "    #         x = self.test_data\n",
    "    #\n",
    "    #     #1. vrstva\n",
    "    #     #x1 =  #nezapomente na bias(prvni sloupec) #4500x401\n",
    "    #     #u1 = ...\n",
    "    #\n",
    "    #     x1 = np.hstack((np.ones((x.shape[0],1)),x))\n",
    "    #     u1 = np.dot(x1,self.w1.T)\n",
    "    #\n",
    "    #     #aktivacni funkce pomocí funkce self.activation_function\n",
    "    #     #a1 = ... #4500x25\n",
    "    #     a1 = self.activation_function(u1)\n",
    "    #\n",
    "    #     #2. vrstva (skryta vrstva)\n",
    "    #     #x2 = ... #4500x26\n",
    "    #     #u2 = ...\n",
    "    #\n",
    "    #     x2 = np.hstack((np.ones((a1.shape[0],1)),a1))\n",
    "    #     u2 = np.dot(x2,self.w2.T)\n",
    "    #\n",
    "    #     #vystup po softmaxu\n",
    "    #     #scores = ... #4500x10 scores pro kazdou tridu\n",
    "    #     scores = softmax(u2)\n",
    "    #\n",
    "    #     #cache\n",
    "    #     self.scores = scores\n",
    "    #     self.a1 = a1\n",
    "    #\n",
    "    #     return scores\n",
    "\n",
    "    def forward(self, mode='training'):\n",
    "        if mode == 'training':\n",
    "            x = self.input_data\n",
    "        else:\n",
    "            x = self.test_data\n",
    "\n",
    "        # 1. vrstva\n",
    "        x1 = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "        u1 = np.dot(x1, self.w1.T)\n",
    "\n",
    "        # aktivacni funkce pomocí funkce self.activation_function\n",
    "        a1 = self.activation_function(u1)\n",
    "\n",
    "        # 2. vrstva (skryta vrstva)\n",
    "        x2 = np.hstack((np.ones((a1.shape[0], 1)), a1))\n",
    "        u2 = np.dot(x2, self.w2.T)\n",
    "\n",
    "        # vystup po softmaxu\n",
    "        scores = softmax(u2)\n",
    "\n",
    "        # cache\n",
    "        self.scores = scores\n",
    "        self.a1 = a1\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def backward(self):\n",
    "        du2 = self.scores - one_hot_encoding(self.classes)\n",
    "        dw2, db2 = theta_grad(du2, self.a1)\n",
    "        da1 = np.dot(du2, self.w2[:, 1:])  # Adjust dimensions here\n",
    "        du1 = self.activation_function_derivation(da1)\n",
    "        dw1, db1 = theta_grad(du1, self.input_data)\n",
    "\n",
    "        # Reshape db2 to (1, 10) for compatibility with dw2\n",
    "        db2 = db2.reshape(-1, 1)\n",
    "\n",
    "        w2 = np.hstack((db2, dw2))  # Concatenate along axis 1\n",
    "        w1 = np.hstack((db1.reshape(-1, 1), dw1))  # Concatenate along axis 1\n",
    "\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "\n",
    "        return w1, w2\n",
    "\n",
    "    # def forward(self, mode='training'):\n",
    "    #     if mode == 'training':\n",
    "    #         x = self.input_data\n",
    "    #     else:\n",
    "    #         x = self.test_data\n",
    "    #\n",
    "    #     # 1. vrstva\n",
    "    #     x1 = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "    #     u1 = np.dot(x1, self.w1.T)\n",
    "    #\n",
    "    #     # aktivacni funkce pomocí funkce self.activation_function\n",
    "    #     a1 = self.activation_function(u1)\n",
    "    #\n",
    "    #     # 2. vrstva (skryta vrstva)\n",
    "    #     x2 = np.hstack((np.ones((a1.shape[0], 1)), a1))\n",
    "    #     u2 = np.dot(x2, self.w2.T)\n",
    "    #\n",
    "    #     # vystup po softmaxu\n",
    "    #     scores = softmax(u2)\n",
    "    #\n",
    "    #     # cache\n",
    "    #     self.scores = scores\n",
    "    #     self.a1 = a1\n",
    "    #\n",
    "    #     return scores\n",
    "    #\n",
    "    #\n",
    "    # def backward(self):\n",
    "    #     du2 = self.scores - one_hot_encoding(self.classes)\n",
    "    #     dw2, db2 = theta_grad(du2, self.a1)\n",
    "    #     da1 = np.dot(du2, self.w2)\n",
    "    #     du1 = self.activation_function_derivation(da1)\n",
    "    #     dw1, db1 = theta_grad(du1, self.input_data)\n",
    "    #\n",
    "    #     # Reshape db2 to (10, 1) for compatibility with dw2\n",
    "    #     db2 = db2.reshape(-1, 1)\n",
    "    #\n",
    "    #     w2 = np.concatenate((db2, dw2), axis=1)\n",
    "    #     w1 = np.concatenate((db1.reshape(-1, 1), dw1), axis=1)\n",
    "    #\n",
    "    #     self.w1 = w1\n",
    "    #     self.w2 = w2\n",
    "    #\n",
    "    #     return w1, w2\n",
    "\n",
    "\n",
    "\n",
    "    # def backward(self):\n",
    "    #\n",
    "    #\n",
    "    #     #pomocí self.scores, self.classes a one_hot_encoding\n",
    "    #     du2 = self.scores - one_hot_encoding(self.classes)\n",
    "    #\n",
    "    #     #pomocí funkce theta_grad\n",
    "    #     #dw2, db2 =\n",
    "    #     dw2, db2 = theta_grad(du2,self.a1)\n",
    "    #\n",
    "    #     #da1 = ...\n",
    "    #     da1 = np.dot(du2,self.w2)\n",
    "    #\n",
    "    #     #pomocí funkce self.activation_function_derivation\n",
    "    #     #POZOR: tato funce se musí aplikovat na vstupní hodnotu z dopředného průchodu !!\n",
    "    #    # du1 =  ...\n",
    "    #     du1 = self.activation_function_derivation(da1)\n",
    "    #\n",
    "    #     #pomocí funkce theta_grad\n",
    "    #     #dw1, db1 = ...\n",
    "    #     dw1, db1 = theta_grad(du1,self.input_data)\n",
    "    #\n",
    "    #     #POZOR: dw2 není gradient celé matice w2 ale pouze její části\n",
    "    #     #gradient celé matice w2 pro update vah vznikne vhodným spojením dw2 a db2\n",
    "    #     #w2 = ...\n",
    "    #     w2 = np.vstack((db2,dw2))\n",
    "    #\n",
    "    #     #obdobně dw1 není gradient celé matice w1 !!\n",
    "    #     #w1 = ...\n",
    "    #     w1 = np.vstack((db1,dw1))\n",
    "    #\n",
    "    #     self.w1 = w1\n",
    "    #     self.w2 = w2\n",
    "    #\n",
    "    #     return w1, w2\n",
    "    \n",
    "    def accuracy(self):\n",
    "        scores = self.forward('test')\n",
    "        predicted_classes = np.argmax(scores,axis=1)\n",
    "        return (predicted_classes==self.test_classes.T).mean() * 100\n",
    "\n",
    "\n",
    "    def setWeigtsForTest(self,w1,w2):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "            \n",
    "#################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-25T19:33:54.919502Z",
     "end_time": "2023-05-25T19:33:54.926845Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "output_size = len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-25T19:36:15.955931Z",
     "end_time": "2023-05-25T19:36:16.002743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.88910953e-01 1.18307825e-04 9.44813682e-01 9.87532276e-01\n",
      " 9.61459910e-01 1.31154023e-02 9.79568046e-01 7.05262715e-01\n",
      " 5.76467884e-03 9.19662205e-01 9.97263993e-01 9.08968353e-01\n",
      " 3.54340337e-03 1.54639813e-01 3.48157918e-03 9.64035515e-01\n",
      " 6.28337854e-04 7.80228020e-03 1.46816393e-01 9.29857033e-01\n",
      " 9.88740224e-01 4.21889681e-02 9.95978182e-01 1.23596237e-02\n",
      " 3.08083417e-02]\n",
      "[1.70049726e-05 1.30427018e-04 6.67761717e-07 2.30092641e-02\n",
      " 5.11252228e-03 3.23657653e-04 2.31894141e-04 5.87981895e-04\n",
      " 9.70496699e-01 8.98808528e-05]\n",
      "[ 0.00019363 -0.00235209 -0.00447712  0.14662094  0.18147318  0.10525905\n",
      "  0.0194968 ]\n",
      "[-3.85991324 -3.51182657  1.1981292  -2.17709937 -2.08968414 -5.8841679\n",
      " -3.18974293 -0.40204105  0.12980703 -2.66511973 -1.68664544 -0.27306076\n",
      " -3.45477212 -3.95876339 -4.89815341 -0.78026439 -1.03196138 -1.01727979\n",
      "  3.40311487  0.71324561  0.21604289 -2.5685545  -2.3717602  -4.52772133\n",
      " -2.5501298  -2.61207791]\n"
     ]
    }
   ],
   "source": [
    "#Instance pro odladění:\n",
    "\n",
    "testTlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size,\n",
    "                         sigmoid, sigmoid_grad, \n",
    "                         alpha = 0.0005, lmbd=0)\n",
    "testTlp.setWeigtsForTest(w1test,w2test)\n",
    "\n",
    "scores = testTlp.forward()\n",
    "print(testTlp.a1[0]) \n",
    "print(scores[3]) \n",
    "w1, w2 = testTlp.backward()\n",
    "print(w1[1,3:10])\n",
    "print(w2[2,:])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro ladění:\n",
    "[9.88910953e-01 1.18307825e-04 9.44813682e-01 9.87532276e-01\n",
    " 9.61459910e-01 1.31154023e-02 9.79568046e-01 7.05262715e-01\n",
    " 5.76467884e-03 9.19662205e-01 9.97263993e-01 9.08968353e-01\n",
    " 3.54340337e-03 1.54639813e-01 3.48157918e-03 9.64035515e-01\n",
    " 6.28337854e-04 7.80228020e-03 1.46816393e-01 9.29857033e-01\n",
    " 9.88740224e-01 4.21889681e-02 9.95978182e-01 1.23596237e-02\n",
    " 3.08083417e-02]\n",
    "[1.70049726e-05 1.30427018e-04 6.67761717e-07 2.30092641e-02\n",
    " 5.11252228e-03 3.23657653e-04 2.31894141e-04 5.87981895e-04\n",
    " 9.70496699e-01 8.98808528e-05]\n",
    "[ 1.04783135e-06 -6.15187918e-06 -3.09972922e-05 -5.11502892e-04\n",
    " -1.01684694e-03 -1.00431299e-03  1.41514706e-04]\n",
    "[-0.68741076 -1.94362559  2.01300712 -3.12207333 -0.23513146  1.38975155\n",
    "  0.91141916 -1.54754314 -0.79837387 -0.65466578  0.73622662 -2.58579641\n",
    "  0.47383578  0.55547437  2.51500361 -2.41635527 -1.63847029  1.20323884\n",
    " -1.20416007 -1.83481622 -1.88023829 -0.33927671  0.23811071 -1.05911533\n",
    "  1.02886739 -0.47560228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-25T19:33:59.728152Z",
     "end_time": "2023-05-25T19:34:04.054248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6752/402714397.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  sig = np.exp(u)/(1+np.exp(u))\n",
      "/tmp/ipykernel_6752/402714397.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  sig = np.exp(u)/(1+np.exp(u))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid testovaci mnozina : 9.0\n"
     ]
    }
   ],
   "source": [
    "tlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size, \n",
    "                         sigmoid, sigmoid_grad, \n",
    "                         alpha = 0.0005, lmbd=0.002)\n",
    "\n",
    "nIter = 150\n",
    "#################################################################\n",
    "\n",
    "for i in range(nIter):\n",
    "            \n",
    "    scores = tlp.forward()\n",
    "    w1, w2 = tlp.backward()\n",
    "    \n",
    "pred = tlp.accuracy()\n",
    "#################################################################\n",
    "print(f\"sigmoid testovaci mnozina : {pred}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-25T19:34:29.682209Z",
     "end_time": "2023-05-25T19:34:33.125384Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6752/3033433357.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  e = np.exp(u)\n",
      "/tmp/ipykernel_6752/3033433357.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  y = e / np.array(np.sum(e,axis=1), ndmin=2).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu testovaci mnozina : 9.0\n"
     ]
    }
   ],
   "source": [
    "tlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size,\n",
    "                         relu, relu_grad, 0.00015, 0)\n",
    "\n",
    "nIter = 150\n",
    "#################################################################\n",
    "\n",
    "for i in range(nIter):\n",
    "            \n",
    "    scores = tlp.forward()\n",
    "    w1, w2 = tlp.backward()\n",
    "    \n",
    "pred = tlp.accuracy()\n",
    "#################################################################\n",
    "print(f\"relu testovaci mnozina : {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
