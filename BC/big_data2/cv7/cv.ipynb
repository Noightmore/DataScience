{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CV 7\n",
    "\n",
    " to install netcat:\n",
    "    apt update\n",
    "    apt-get install netcat\n",
    "    nc -lkp 9999 &"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0b6e78e937423c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, lower, col,regexp_replace\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NetworkWordCount\").getOrCreate()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T09:30:15.266798076Z",
     "start_time": "2023-12-15T09:30:14.899791224Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T09:30:11.884719721Z",
     "start_time": "2023-12-15T09:30:11.367105692Z"
    }
   },
   "id": "aa8f0b23ead78357"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/15 10:30:19 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-5b495670-93a2-4cd1-816f-36a6b6cdea3e. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/12/15 10:30:19 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "+-----+----+-----+\n",
      "|start|word|count|\n",
      "+-----+----+-----+\n",
      "+-----+----+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "|start|word|count|\n",
      "+-----+----+-----+\n",
      "+-----+----+-----+\n",
      "+------------------------------------------+--------+-----+\n",
      "|start                                     |word    |count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|{2023-12-15 10:30:15, 2023-12-15 10:30:45}|text    |2    |\n",
      "|{2023-12-15 10:30:15, 2023-12-15 10:30:45}|stffysaf|1    |\n",
      "+------------------------------------------+--------+-----+\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 33\u001B[0m\n\u001B[1;32m     25\u001B[0m latest_window_query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124mSELECT *\u001B[39m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124mFROM my_query\u001B[39m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124mWHERE start = (SELECT MAX(start) FROM my_query)\u001B[39m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124m\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     31\u001B[0m spark\u001B[38;5;241m.\u001B[39msql(latest_window_query)\u001B[38;5;241m.\u001B[39mshow(truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 33\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, lower, col,regexp_replace,current_timestamp, window, desc\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NetworkWordCount\").getOrCreate()\n",
    "lines = spark.readStream.option('newFilesOnly', 'true').text('./data')\n",
    "#lines = spark.readStream.format(\"socket\").option(\"host\", \"localhost\").option(\"port\", 9999).load()\n",
    "\n",
    "words = lines.select(explode(split(lines.value, \" \")).alias(\"word\"))\n",
    "\n",
    "words = words.select(lower(col('word')).alias('word'))\n",
    "words = words.withColumn('word', regexp_replace('word', r'[^\\s\\w]', ''))\n",
    "words = words.filter(\"word != ''\")\n",
    "\n",
    "words = words.withColumn('eventTime', current_timestamp())\n",
    "wordCounts = words.groupBy(window(col(\"eventTime\"), \"30 seconds\", \"15 seconds\").alias('start'), col(\"word\")).count()\n",
    "wordSorted = wordCounts.orderBy(\"start\",desc(\"count\"))\n",
    "\n",
    "\n",
    "query = wordSorted.writeStream.outputMode(\"complete\").format(\"memory\").queryName(\"my_query\").start()\n",
    "\n",
    "while True:\n",
    "    #spark.sql_scripts(\"SELECT * FROM my_query\").show(truncate=False)\n",
    "    # just show 1 window each time\n",
    "    latest_window_query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM my_query\n",
    "    WHERE start = (SELECT MAX(start) FROM my_query)\n",
    "    \"\"\"\n",
    "\n",
    "    spark.sql(latest_window_query).show(truncate=False)\n",
    "\n",
    "    time.sleep(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T09:30:37.267206119Z",
     "start_time": "2023-12-15T09:30:19.691063239Z"
    }
   },
   "id": "9b69891da54f2c94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# cv 7 bonus"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eb1a9ff573a76b1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/15 10:35:29 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-3b337c8c-2b90-4aa6-9c7d-4fcc7aaaedd5. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/12/15 10:35:29 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "23/12/15 10:35:29 WARN FileStreamSource: 'latestFirst' is true. New files will be processed first, which may affect the watermark\n",
      "value. In addition, 'maxFileAge' will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|   hokus|    1|\n",
      "|  txtetx|    1|\n",
      "|stffysaf|    1|\n",
      "|    text|    6|\n",
      "|   pokus|    1|\n",
      "+--------+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:(190 + 8) / 200][Stage 48:> (0 + 0) / 200][Stage 49:>   (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|   hokus|    1|\n",
      "|stffysaf|    1|\n",
      "|    text|    4|\n",
      "|   pokus|    1|\n",
      "+--------+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "|hokus|    1|\n",
      "| text|    2|\n",
      "|pokus|    1|\n",
      "+-----+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "|hokus|    1|\n",
      "|  txt|    1|\n",
      "| text|    2|\n",
      "|pokus|    1|\n",
      "+-----+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rob/Programming/DataScience/venv/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rob/Programming/DataScience/venv/lib/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 40\u001B[0m\n\u001B[1;32m     33\u001B[0m query \u001B[38;5;241m=\u001B[39m word_counts \\\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;241m.\u001B[39mwriteStream \\\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;241m.\u001B[39moutputMode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcomplete\u001B[39m\u001B[38;5;124m\"\u001B[39m) \\\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconsole\u001B[39m\u001B[38;5;124m\"\u001B[39m) \\\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# Čekání na ukončení streaming query\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m \u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mawaitTermination\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/DataScience/venv/lib/python3.11/site-packages/pyspark/sql/streaming.py:107\u001B[0m, in \u001B[0;36mStreamingQuery.awaitTermination\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsq\u001B[38;5;241m.\u001B[39mawaitTermination(\u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m))\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mawaitTermination\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/DataScience/venv/lib/python3.11/site-packages/py4j/java_gateway.py:1320\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1313\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m-> 1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1322\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[0;32m~/Programming/DataScience/venv/lib/python3.11/site-packages/py4j/java_gateway.py:1038\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1036\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_connection()\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1038\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n\u001B[1;32m   1040\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection_guard(connection)\n",
      "File \u001B[0;32m~/Programming/DataScience/venv/lib/python3.11/site-packages/py4j/clientserver.py:511\u001B[0m, in \u001B[0;36mClientServerConnection.send_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 511\u001B[0m         answer \u001B[38;5;241m=\u001B[39m smart_decode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream\u001B[38;5;241m.\u001B[39mreadline()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    512\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer received: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(answer))\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001B[39;00m\n\u001B[1;32m    514\u001B[0m         \u001B[38;5;66;03m# answer before the socket raises an error.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.11/socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, current_timestamp, lower, regexp_replace\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "\n",
    "# Inicializace SparkSession\n",
    "spark = SparkSession.builder.appName(\"WordCountTxtFileStreaming\").getOrCreate()\n",
    "\n",
    "# Definice schématu pro stream souborů\n",
    "schema = StructType([StructField(\"value\", StringType()), StructField(\"timestamp\", TimestampType())])\n",
    "\n",
    "# Definice schématu pro stream souborů\n",
    "lines = spark.readStream.format(\"csv\") \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"latestFirst\", \"true\") \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .option(\"filter\", \"input_file_name LIKE '%.txt'\") \\\n",
    "    .load(\"./data/*\")\n",
    "\n",
    "# Přidání sloupce timestamp\n",
    "lines_with_timestamp = lines.withColumn(\"timestamp\", current_timestamp())\n",
    "\n",
    "# Převedení na malá písmena a odstranění interpunkce\n",
    "cleaned_lines = lines_with_timestamp.withColumn(\"cleaned_value\", regexp_replace(lower(lines_with_timestamp.value), \"[^a-z\\\\s]\", \"\"))\n",
    "\n",
    "# Rozdělení řádků na slova\n",
    "words = cleaned_lines.select(explode(split(cleaned_lines.cleaned_value, \" \")).alias(\"word\"), \"timestamp\")\n",
    "\n",
    "# Definice schématu pro stream\n",
    "word_counts = words.groupBy(\"word\").count()\n",
    "\n",
    "# Výpis výsledků na konzoli\n",
    "query = word_counts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "# Čekání na ukončení streaming query\n",
    "query.awaitTermination()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T09:38:15.775734177Z",
     "start_time": "2023-12-15T09:35:29.372696078Z"
    }
   },
   "id": "e8148640de7fab2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
