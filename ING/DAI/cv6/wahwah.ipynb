{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-20T11:18:38.313209Z",
     "start_time": "2025-03-20T11:18:38.297961Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio as ta\n",
    "import sounddevice as sd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "doba = 10    # v sekundach\n",
    "\n",
    "mylist = sd.query_devices()\n",
    "\n",
    "def callback(outdata, frames, time, status):\n",
    "    global current_sample, waveform_hovor, waveform_guitar, n_samples, sample_rate, a, f, wave\n",
    "    if status:\n",
    "        print(status)\n",
    "\n",
    "    # Extract the next chunk of frames for both signals\n",
    "    chunk_hovor = waveform_hovor[current_sample:current_sample+frames]\n",
    "    chunk_guitar = waveform_guitar[current_sample:current_sample+frames]\n",
    "\n",
    "    # Apply tremolo modulation only to the guitar chunk:\n",
    "    n_vals = np.arange(current_sample, current_sample + len(chunk_guitar))\n",
    "    envelope = (1 - a) + a * np.abs(np.sin(np.pi * f * (n_vals / sample_rate)))**wave\n",
    "    envelope = envelope[:, np.newaxis]  # reshape for broadcasting (if multi-channel)\n",
    "    modulated_chunk_guitar = chunk_guitar * envelope\n",
    "\n",
    "    # If the chunks are shorter than the requested frames (at the end), pad with zeros.\n",
    "    if len(chunk_hovor) < frames:\n",
    "        pad = np.zeros((frames - len(chunk_hovor), chunk_hovor.shape[1]))\n",
    "        chunk_hovor = np.vstack((chunk_hovor, pad))\n",
    "    if len(modulated_chunk_guitar) < frames:\n",
    "        pad = np.zeros((frames - len(modulated_chunk_guitar), modulated_chunk_guitar.shape[1]))\n",
    "        modulated_chunk_guitar = np.vstack((modulated_chunk_guitar, pad))\n",
    "\n",
    "    # Mix the two signals (add them together)\n",
    "    mixed_chunk = chunk_hovor + 3*modulated_chunk_guitar\n",
    "\n",
    "    # Write the mixed audio to the output buffer\n",
    "    outdata[:] = mixed_chunk\n",
    "\n",
    "    # Advance the global sample pointer\n",
    "    current_sample += frames\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:22:00.775925Z",
     "start_time": "2025-03-20T11:21:28.221153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths to your audio files:\n",
    "audio_path_hovor = './hovor_doprovod.wav'\n",
    "audio_path_guitar = './hovor_guitar_flanger_reverb.wav'\n",
    "\n",
    "# Load both audio files using torchaudio\n",
    "waveform_hovor, sr_hovor = ta.load(audio_path_hovor)  # shape: [channels, samples]\n",
    "waveform_guitar, sr_guitar = ta.load(audio_path_guitar)  # shape: [channels, samples]\n",
    "\n",
    "# Ensure the sample rates match\n",
    "if sr_hovor != sr_guitar:\n",
    "    raise ValueError(\"Sample rates do not match!\")\n",
    "sample_rate = sr_hovor\n",
    "\n",
    "# Transpose to shape [samples, channels] and convert to NumPy arrays\n",
    "waveform_hovor = waveform_hovor.T.numpy()\n",
    "waveform_guitar = waveform_guitar.T.numpy()\n",
    "\n",
    "# Determine the number of samples to use (the minimum of the two)\n",
    "n_samples = min(waveform_hovor.shape[0], waveform_guitar.shape[0])\n",
    "current_sample = 0  # Global pointer\n",
    "\n",
    "# Tremolo parameters for the guitar signal\n",
    "a = 0.5  # modulation depth\n",
    "f = 1     # modulation frequency in Hz (adjust as needed)\n",
    "wave = 4  # ???????\n",
    "\n",
    "# Create an OutputStream and play the mixed audio.\n",
    "with sd.OutputStream(channels=waveform_hovor.shape[1],\n",
    "                     samplerate=sample_rate,\n",
    "                     callback=callback):\n",
    "    # Keep the stream open for the duration of the shorter file.\n",
    "    sd.sleep(int((n_samples / sample_rate) * 1000))"
   ],
   "id": "20c3cf70ad4e6b95",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reverb + tremelo -> hnusne to zni\n",
    "# lepsi: reverb + tremolo\n",
    "# jsou to nelinearni efekty!\n",
    "# tremolo neni casove invariatni -> nelinearni!"
   ],
   "id": "e56b3efcee842e3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### vibrato\n",
    "\n",
    "# matblad zaklinadla:\n",
    "# clc, clear all, close all\n",
    "\n",
    "# [data, fs] = audioread('hovor_doprovod.wav');\n",
    "# N = length(data);\n",
    "# y = zeros(size(x));\n",
    "#\n",
    "# fr = 2\n",
    "# depth = 100\n",
    "# for n = 100:N-100\n",
    "#    time = n/fs;\n",
    "#    LFO = depth*sin(2*pi*fr*time) + 50; % +50 na chorus\n",
    "#    M = fix(LFO);\n",
    "#    gamma = LFO - M;\n",
    "#    y(n,:) = data(n,:) + (1-gamma)*data(n-M,:) + gamma*data(n-M-1,:); % plus efekt chorus\n",
    "#    % y(n,:) = (1-gamma)*data(n-M,:) + gamma*data(n-M-1,:); % metoda linearni interpolace\n",
    "#    % y(n,:) data(n-round(LFO),:);\n",
    "# end\n",
    "\n",
    "# soundsc(y,fs)\n",
    "#\n",
    "# stereofonni efekt, slysitelny ve sluchatka hlavne, prijemny efekt:\n",
    "# y(n,1) = data(n,1) + (1-gamma)*data(n-M,1) + gamma*data(n-M-1,1);\n",
    "# y(n,2) = data(n,2) - (1-gamma)*data(n-M,2) - gamma*data(n-M-1,2);"
   ],
   "id": "bc3a1957e966800f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
